# NPC Tumor Report Generation System

Há»‡ thá»‘ng phÃ¢n tÃ­ch vÃ  táº¡o bÃ¡o cÃ¡o khá»‘i u vÃ²m há»ng (Nasopharyngeal Carcinoma) sá»­ dá»¥ng AI.

## ğŸŒŸ TÃ­nh nÄƒng

- **PhÃ¢n Ä‘oáº¡n khá»‘i u**: Sá»­ dá»¥ng U-Net Ä‘á»ƒ phÃ¢n Ä‘oáº¡n GTV (Gross Tumor Volume)
- **PhÃ¢n tÃ­ch tá»± Ä‘á»™ng**: TrÃ­ch xuáº¥t Ä‘áº·c Ä‘iá»ƒm khá»‘i u (thá»ƒ tÃ­ch, kÃ­ch thÆ°á»›c, hÃ¬nh thÃ¡i)
- **Trá»±c quan hÃ³a**: Táº¡o hÃ¬nh áº£nh multi-slice, 3-plane view
- **BÃ¡o cÃ¡o AI**: Sá»­ dá»¥ng Gemini 2.0 Flash Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o y khoa
- **Chat tÆ°Æ¡ng tÃ¡c**: Há»i Ä‘Ã¡p vá» káº¿t quáº£ phÃ¢n tÃ­ch
- **API Backend**: FastAPI vá»›i RESTful endpoints
- **Web UI**: Gradio interface dá»… sá»­ dá»¥ng

## ğŸ“ Cáº¥u trÃºc project

```
npc_system/
â”œâ”€â”€ __init__.py          # Package initialization
â”œâ”€â”€ config.py            # Configuration management
â”œâ”€â”€ models.py            # U-Net model & tumor analysis
â”œâ”€â”€ gemini_service.py    # Gemini API integration
â”œâ”€â”€ visualization.py     # Visualization generation
â”œâ”€â”€ pipeline.py          # Main processing pipeline
â”œâ”€â”€ api.py               # FastAPI backend
â”œâ”€â”€ gradio_ui.py         # Gradio web interface
â”œâ”€â”€ run.py               # Main entry point
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ Dockerfile           # Docker configuration
â”œâ”€â”€ docker-compose.yml   # Docker Compose setup
â””â”€â”€ README.md            # Documentation
```

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone vÃ  cÃ i Ä‘áº·t dependencies

```bash
cd npc_system
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh

Copy file `.env.example` thÃ nh `.env` vÃ  Ä‘iá»n API key:

```bash
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

### 3. Cháº¡y há»‡ thá»‘ng

#### Cháº¡y Gradio Web UI:
```bash
python run.py gradio
```

#### Cháº¡y FastAPI Backend:
```bash
python run.py api
```

#### Cháº¡y cáº£ hai:
```bash
python run.py both
```

## ğŸ³ Cháº¡y vá»›i Docker

```bash
# Build vÃ  cháº¡y
docker-compose up -d

# Xem logs
docker-compose logs -f

# Dá»«ng
docker-compose down
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | MÃ´ táº£ |
|--------|----------|-------|
| GET | `/` | Root endpoint |
| GET | `/health` | Health check |
| GET | `/cases` | Danh sÃ¡ch cases |
| POST | `/process` | Xá»­ lÃ½ case |
| POST | `/process/stream` | Xá»­ lÃ½ vá»›i streaming |
| POST | `/upload` | Upload vÃ  xá»­ lÃ½ file |
| POST | `/chat` | Chat vá»›i AI |
| GET | `/chat/history` | Lá»‹ch sá»­ chat |
| POST | `/chat/reset` | Reset chat session |
| GET | `/reports` | Danh sÃ¡ch bÃ¡o cÃ¡o |
| GET | `/reports/{id}` | Chi tiáº¿t bÃ¡o cÃ¡o |
| GET | `/reports/{id}/image/{type}` | HÃ¬nh áº£nh bÃ¡o cÃ¡o |

## ğŸ–¥ï¸ Gradio Interface

Truy cáº­p: `http://localhost:7860`

### Tabs:
1. **ğŸ“ Xá»­ lÃ½ Case**: Chá»n hoáº·c upload file HDF5
2. **ğŸ’¬ Há»i Ä‘Ã¡p AI**: Chat vá» káº¿t quáº£ phÃ¢n tÃ­ch
3. **âš™ï¸ CÃ i Ä‘áº·t**: Cáº¥u hÃ¬nh há»‡ thá»‘ng

## ğŸ“Š API Usage Examples

### Python
```python
import requests

# Process a case
response = requests.post(
    "http://localhost:8000/process",
    json={
        "filename": "OA_CenterA_ano_set_A_005.h5",
        "dataset": "test",
        "generate_report": True
    }
)
result = response.json()
print(result['report'])

# Chat about results
response = requests.post(
    "http://localhost:8000/chat",
    json={"message": "Giáº£i thÃ­ch sphericity"}
)
print(response.json()['response'])
```

### cURL
```bash
# Process case
curl -X POST "http://localhost:8000/process" \
  -H "Content-Type: application/json" \
  -d '{"filename": "OA_CenterA_ano_set_A_005.h5", "dataset": "test"}'

# Chat
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Khá»‘i u cÃ³ nghiÃªm trá»ng khÃ´ng?"}'
```

## ğŸ”§ Configuration

CÃ¡c cáº¥u hÃ¬nh chÃ­nh trong `config.py`:

| Config | MÃ´ táº£ | Default |
|--------|-------|---------|
| `model.model_path` | Path Ä‘áº¿n U-Net model | `outputs/.../unet_best_model.pth` |
| `model.device` | Device (cuda/cpu) | `cuda` |
| `gemini.model_name` | Gemini model | `gemini-2.0-flash` |
| `gemini.temperature` | Temperature | `0.3` |
| `server.api_port` | API port | `8000` |
| `server.gradio_port` | Gradio port | `7860` |

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
