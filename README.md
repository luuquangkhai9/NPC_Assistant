# NPC Tumor Report Generation System

Há»‡ thá»‘ng phÃ¢n tÃ­ch vÃ  táº¡o bÃ¡o cÃ¡o khá»‘i u vÃ²m há»ng (Nasopharyngeal Carcinoma) sá»­ dá»¥ng AI.

## ğŸŒŸ TÃ­nh nÄƒng

- **PhÃ¢n Ä‘oáº¡n khá»‘i u**: Sá»­ dá»¥ng U-Net Ä‘á»ƒ phÃ¢n Ä‘oáº¡n GTV (Gross Tumor Volume)
- **PhÃ¢n tÃ­ch tá»± Ä‘á»™ng**: TrÃ­ch xuáº¥t Ä‘áº·c Ä‘iá»ƒm khá»‘i u (thá»ƒ tÃ­ch, kÃ­ch thÆ°á»›c, hÃ¬nh thÃ¡i)
- **Trá»±c quan hÃ³a**: Táº¡o hÃ¬nh áº£nh multi-slice, 3-plane view
- **BÃ¡o cÃ¡o AI**: Sá»­ dá»¥ng Gemini 3 pro Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o y khoa
- **Chat tÆ°Æ¡ng tÃ¡c**: Há»i Ä‘Ã¡p vá» káº¿t quáº£ phÃ¢n tÃ­ch
- **API Backend**: FastAPI vá»›i RESTful endpoints
- **Web UI**: Gradio interface dá»… sá»­ dá»¥ng

## ğŸ“ Cáº¥u trÃºc project

```
.
â”œâ”€â”€ convert_data.py      # Script chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u
â”œâ”€â”€ training_pipeline.ipynb # Notebook huáº¥n luyá»‡n U-Net
â”œâ”€â”€ trainning_swinunet.ipynb # Notebook huáº¥n luyá»‡n Swin-UNet
â”œâ”€â”€ npc_system/          # Package source code
â”‚   â”œâ”€â”€ __init__.py      # Package initialization
â”‚   â”œâ”€â”€ config.py        # Configuration management
â”‚   â”œâ”€â”€ models.py        # U-Net model & tumor analysis
â”‚   â”œâ”€â”€ gemini_service.py # Gemini API integration
â”‚   â”œâ”€â”€ visualization.py # Visualization generation
â”‚   â”œâ”€â”€ pipeline.py      # Main processing pipeline
â”‚   â”œâ”€â”€ api.py           # FastAPI backend
â”‚   â”œâ”€â”€ gradio_ui.py     # Gradio web interface
â”‚   â”œâ”€â”€ run.py           # Main entry point
â”‚   â”œâ”€â”€ requirements.txt # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile       # Docker configuration
â”‚   â””â”€â”€ docker-compose.yml # Docker Compose setup
â””â”€â”€ README.md            # Documentation
```

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone vÃ  cÃ i Ä‘áº·t dependencies

```bash
cd npc_system
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh

Copy file `.env.example` thÃ nh `.env` vÃ  Ä‘iá»n API key:

```bash
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY
```

### 3. Cháº¡y há»‡ thá»‘ng

#### Cháº¡y Gradio Web UI:
```bash
python run.py gradio
```

#### Cháº¡y FastAPI Backend:
```bash
python run.py api
```

<!-- uvicorn api:app --host 0.0.0.0 --port 8000 --reload -->

#### Cháº¡y cáº£ hai:
```bash
python run.py both
```

## ï¿½ï¸ Chuáº©n bá»‹ dá»¯ liá»‡u & Training
### 0. Táº£i dá»¯ liá»‡u
Dá»¯ liá»‡u sá»­ dá»¥ng trong dá»± Ã¡n Ä‘Æ°á»£c cung cáº¥p bá»Ÿi bÃ i bÃ¡o [SFADA-GTV-Seg](https://www.redjournal.org/article/S0360-3016(24)03644-7/fulltext).

Báº¡n cÃ³ thá»ƒ táº£i dataset tá»« Google Drive:
- **Link táº£i**: [Google Drive Folder](https://drive.google.com/drive/folders/1y7GNrIqkqzebyJhaO-G1rDvs1OhCVYgh)

Sau khi táº£i vá», hÃ£y giáº£i nÃ©n vÃ  sáº¯p xáº¿p thÆ° má»¥c nhÆ° hÆ°á»›ng dáº«n bÃªn dÆ°á»›i.
### 1. Cáº¥u trÃºc dá»¯ liá»‡u Ä‘áº§u vÃ o
Dá»¯ liá»‡u NIfTI cáº§n Ä‘Æ°á»£c tá»• chá»©c theo cáº¥u trÃºc sau:
```
dataset_root/
â”œâ”€â”€ CenterA/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ case001.nii.gz
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ case001.nii.gz
â”‚       â””â”€â”€ ...
â”œâ”€â”€ CenterB/
â”‚   â””â”€â”€ ...
```

### 2. Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u
Sá»­ dá»¥ng script `convert_data.py` Ä‘á»ƒ chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u NIfTI sang Ä‘á»‹nh dáº¡ng `.npz` (cho training) vÃ  `.h5` (cho validation/test).

```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t (náº¿u chÆ°a cÃ³)
pip install h5py SimpleITK scipy tqdm scikit-image

# Cháº¡y chuyá»ƒn Ä‘á»•i
python convert_data.py --dataset-root /path/to/your/dataset --output-root ./outputs/swin_dataset_npz
```

CÃ¡c tham sá»‘ tÃ¹y chá»n:
- `--img-size`: KÃ­ch thÆ°á»›c áº£nh (máº·c Ä‘á»‹nh 224)
- `--force`: Báº¯t buá»™c chuyá»ƒn Ä‘á»•i láº¡i tá»« Ä‘áº§u

### 3. Huáº¥n luyá»‡n mÃ´ hÃ¬nh
Sá»­ dá»¥ng cÃ¡c notebook trong thÆ° má»¥c gá»‘c Ä‘á»ƒ huáº¥n luyá»‡n:
- `trainning_swinunet.ipynb`: Huáº¥n luyá»‡n Swin-UNet (khuyÃªn dÃ¹ng)
- `training_pipeline.ipynb`: Huáº¥n luyá»‡n U-Net cÆ¡ báº£n

## ï¿½ğŸ³ Cháº¡y vá»›i Docker

```bash
# Build vÃ  cháº¡y
docker-compose up -d

# Xem logs
docker-compose logs -f

# Dá»«ng
docker-compose down
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | MÃ´ táº£ |
|--------|----------|-------|
| GET | `/` | Root endpoint |
| GET | `/health` | Health check |
| GET | `/cases` | Danh sÃ¡ch cases |
| POST | `/process` | Xá»­ lÃ½ case |
| POST | `/process/stream` | Xá»­ lÃ½ vá»›i streaming |
| POST | `/upload` | Upload vÃ  xá»­ lÃ½ file |
| POST | `/chat` | Chat vá»›i AI |
| GET | `/chat/history` | Lá»‹ch sá»­ chat |
| POST | `/chat/reset` | Reset chat session |
| GET | `/reports` | Danh sÃ¡ch bÃ¡o cÃ¡o |
| GET | `/reports/{id}` | Chi tiáº¿t bÃ¡o cÃ¡o |
| GET | `/reports/{id}/image/{type}` | HÃ¬nh áº£nh bÃ¡o cÃ¡o |

## ğŸ–¥ï¸ Gradio Interface

Truy cáº­p: `http://localhost:7860`

### Tabs:
1. **ğŸ“ Xá»­ lÃ½ Case**: Chá»n hoáº·c upload file HDF5
2. **ğŸ’¬ Há»i Ä‘Ã¡p AI**: Chat vá» káº¿t quáº£ phÃ¢n tÃ­ch
3. **âš™ï¸ CÃ i Ä‘áº·t**: Cáº¥u hÃ¬nh há»‡ thá»‘ng

## ğŸ“Š API Usage Examples

### Python
```python
import requests

# Process a case
response = requests.post(
    "http://localhost:8000/process",
    json={
        "filename": "OA_CenterA_ano_set_A_005.h5",
        "dataset": "test",
        "generate_report": True
    }
)
result = response.json()
print(result['report'])

# Chat about results
response = requests.post(
    "http://localhost:8000/chat",
    json={"message": "Giáº£i thÃ­ch sphericity"}
)
print(response.json()['response'])
```

### cURL
```bash
# Process case
curl -X POST "http://localhost:8000/process" \
  -H "Content-Type: application/json" \
  -d '{"filename": "OA_CenterA_ano_set_A_005.h5", "dataset": "test"}'

# Chat
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "Khá»‘i u cÃ³ nghiÃªm trá»ng khÃ´ng?"}'
```

## ğŸ”§ Configuration

CÃ¡c cáº¥u hÃ¬nh chÃ­nh trong `config.py`:

| Config | MÃ´ táº£ | Default |
|--------|-------|---------|
| `model.model_path` | Path Ä‘áº¿n U-Net model | `outputs/.../unet_best_model.pth` | 
| Path Ä‘áº¿n Swin U-Net model | `outputs/.../swin_best_model.pth` |
| `model.device` | Device (cuda/cpu) | `cuda` |
| `gemini.model_name` | Gemini model | `gemini-3-pro-preview` |
| `gemini.temperature` | Temperature | `0.3` |
| `server.api_port` | API port | `8080` |
| `server.gradio_port` | Gradio port | `7860` |

